{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aaf108ac-f884-47ca-98a9-c3f6ba86c510",
   "metadata": {},
   "source": [
    "# Loading libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6f3e0c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.chdir(\"..\")\n",
    "from pathlib import Path\n",
    "from tqdm.auto import tqdm, trange\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from collections import defaultdict, Counter\n",
    "import numpy as np\n",
    "import pickle\n",
    "import matplotlib\n",
    "import hdbscan\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn_extra.cluster import KMedoids\n",
    "from matplotlib.markers import MarkerStyle\n",
    "from sklearn.metrics import silhouette_samples, silhouette_score\n",
    "import plotly.express as px\n",
    "from matplotlib.colors import ListedColormap\n",
    "from itertools import groupby\n",
    "from terpeneminer.src.structural_algorithms import MappedRegion\n",
    "import warnings\n",
    "\n",
    "warnings.simplefilter(\"ignore\", UserWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7d408eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "terpene_synthases_df = pd.read_csv(\n",
    "    \"data/TPS-Nov19_2023_verified_all_reactions_with_neg_with_folds.csv\"\n",
    ")\n",
    "\n",
    "terpene_synthases_classes = pd.read_csv(\n",
    "    \"data/TPS-reaction-mechanism-classes-cleaned.csv\"\n",
    ")\n",
    "terpene_synthases_df = terpene_synthases_df.drop(\"Class (I or II)\", axis=1).merge(\n",
    "    terpene_synthases_classes[\n",
    "        [\n",
    "            \"Uniprot ID\",\n",
    "            \"Substrate (including stereochemistry)\",\n",
    "            \"Name of product\",\n",
    "            \"Class (I or II)\",\n",
    "        ]\n",
    "    ],\n",
    "    on=[\"Uniprot ID\", \"Substrate (including stereochemistry)\", \"Name of product\"],\n",
    ")\n",
    "terpene_synthases_df.loc[\n",
    "    (terpene_synthases_df[\"Type (mono, sesq, di, …)\"] == \"di-int\"),\n",
    "    \"Type (mono, sesq, di, …)\",\n",
    "] = \"di\"\n",
    "terpene_synthases_df.loc[\n",
    "    (terpene_synthases_df[\"Type (mono, sesq, di, …)\"] == \"di\")\n",
    "    & (terpene_synthases_df[\"Class (I or II)\"] == \"prenyl\"),\n",
    "    \"Type (mono, sesq, di, …)\",\n",
    "] = \"ggpps\"\n",
    "\n",
    "terpene_synthases_df.loc[\n",
    "    terpene_synthases_df[\"Type (mono, sesq, di, …)\"].isin(\n",
    "        {\"ggpps\", \"fpps\", \"gpps\", \"gfpps\", \"hsqs\"}\n",
    "    ),\n",
    "    \"SMILES_substrate_canonical_no_stereo\",\n",
    "] = \"precursor substr\"\n",
    "terpene_synthases_df.loc[\n",
    "    terpene_synthases_df[\"Type (mono, sesq, di, …)\"].isin(\n",
    "        {\"ggpps\", \"fpps\", \"gpps\", \"gfpps\", \"hsqs\"}\n",
    "    ),\n",
    "    \"SMILES_product_canonical_no_stereo\",\n",
    "] = \"precursors\"\n",
    "terpene_synthases_df.loc[\n",
    "    terpene_synthases_df[\"Type (mono, sesq, di, …)\"].isin(\n",
    "        {\"ggpps\", \"fpps\", \"gpps\", \"gfpps\", \"hsqs\"}\n",
    "    ),\n",
    "    \"Type (mono, sesq, di, …)\",\n",
    "] = \"polyprenyl synthetase\"\n",
    "\n",
    "terpene_synthases_df.loc[\n",
    "    (terpene_synthases_df[\"Type (mono, sesq, di, …)\"] == \"polyprenyl synthetase\")\n",
    "    & (terpene_synthases_df[\"Class (I or II)\"] == \"Class I\"),\n",
    "    \"Type (mono, sesq, di, …)\",\n",
    "] = \"hemi\"\n",
    "\n",
    "\n",
    "def get_reaction_type(tps_type, tps_class):\n",
    "    if tps_type in {\"tetra\", \"tetra-int\"}:\n",
    "        return \"tetra\"\n",
    "    if tps_type in {\"sester\", \"sesquar\", \"sesq\", \"hemi\", \"mono\"}:\n",
    "        return tps_type\n",
    "    if tps_type == \"polyprenyl synthetase\":\n",
    "        return \"isoprenyl diphosphate synthase\"\n",
    "    if \"tri\" in tps_type:\n",
    "        if tps_class == \"prenyl\":\n",
    "            return f\"tri (squalene synthase)\"\n",
    "        return f\"tri ({tps_class})\"\n",
    "    if tps_type == \"di\":\n",
    "        return f\"di ({tps_class})\"\n",
    "    return False\n",
    "\n",
    "\n",
    "terpene_synthases_df[\"reaction_type\"] = (\n",
    "    terpene_synthases_df[\"Type (mono, sesq, di, …)\"].map(lambda x: [x])\n",
    "    + terpene_synthases_df[\"Class (I or II)\"].map(lambda x: [x])\n",
    ").map(lambda x: get_reaction_type(*x))\n",
    "terpene_synthases_df = terpene_synthases_df[\n",
    "    terpene_synthases_df[\"reaction_type\"] != False\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c0a265d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_2_substrates_set = terpene_synthases_df.groupby(\"Uniprot ID\")[\n",
    "    \"SMILES_substrate_canonical_no_stereo\"\n",
    "].agg(set)\n",
    "id_2_type_set = terpene_synthases_df.groupby(\"Uniprot ID\")[\"reaction_type\"].agg(set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "15efa052",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27cf83d09aec4804b1167b0ce1069c9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2242 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "TypeError",
     "evalue": "cannot unpack non-iterable MappedRegion object",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 40\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\n\u001b[1;32m     35\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata/tps_domains_and_comparisons/regions_completed_very_confident_all_ALL.pkl\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     36\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     37\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m     38\u001b[0m     regions \u001b[38;5;241m=\u001b[39m pickle\u001b[38;5;241m.\u001b[39mload(f)\n\u001b[0;32m---> 40\u001b[0m dist_mat \u001b[38;5;241m=\u001b[39m \u001b[43mget_dist_mat_precomputed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mregions\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[5], line 8\u001b[0m, in \u001b[0;36mget_dist_mat_precomputed\u001b[0;34m(regions, root_path, selected_indices)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_dist_mat_precomputed\u001b[39m(\n\u001b[1;32m      2\u001b[0m     regions: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mtuple\u001b[39m[\u001b[38;5;28mstr\u001b[39m, MappedRegion]],\n\u001b[1;32m      3\u001b[0m     root_path: Path \u001b[38;5;241m=\u001b[39m Path(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata/tps_domains_and_comparisons/\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m      4\u001b[0m     selected_indices: np\u001b[38;5;241m.\u001b[39mndarray \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m      5\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m np\u001b[38;5;241m.\u001b[39mndarray:\n\u001b[1;32m      6\u001b[0m     dist_mat \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mones((\u001b[38;5;28mlen\u001b[39m(regions), \u001b[38;5;28mlen\u001b[39m(regions)))\n\u001b[0;32m----> 8\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m region_i, (filename, region) \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28menumerate\u001b[39m(regions), total\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(regions)):\n\u001b[1;32m      9\u001b[0m         all_paths \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\n\u001b[1;32m     10\u001b[0m             root_path\u001b[38;5;241m.\u001b[39mglob(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mall_tm_region_very_conf_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mregion_i\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mregion\u001b[38;5;241m.\u001b[39mmodule_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.pkl\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     11\u001b[0m         )\n\u001b[1;32m     12\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m (\n\u001b[1;32m     13\u001b[0m             \u001b[38;5;28mlen\u001b[39m(all_paths) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     14\u001b[0m         ), \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPrecomputed path error for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mregion_i\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mregion\u001b[38;5;241m.\u001b[39mmodule_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m [file \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mall_tm_region_very_conf_*_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mregion\u001b[38;5;241m.\u001b[39mmodule_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.pkl\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]: # of results is \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(all_paths)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mmap\u001b[39m(\u001b[38;5;28mstr\u001b[39m,\u001b[38;5;250m \u001b[39mall_paths))\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "\u001b[0;31mTypeError\u001b[0m: cannot unpack non-iterable MappedRegion object"
     ]
    }
   ],
   "source": [
    "def get_dist_mat_precomputed(\n",
    "    regions: list[tuple[str, MappedRegion]],\n",
    "    root_path: Path = Path(f\"data/tps_domains_and_comparisons/\"),\n",
    "    selected_indices: np.ndarray = None,\n",
    ") -> np.ndarray:\n",
    "    dist_mat = np.ones((len(regions), len(regions)))\n",
    "\n",
    "    for region_i, (filename, region) in tqdm(enumerate(regions), total=len(regions)):\n",
    "        all_paths = list(\n",
    "            root_path.glob(f\"all_tm_region_very_conf_{region_i}_{region.module_id}.pkl\")\n",
    "        )\n",
    "        assert (\n",
    "            len(all_paths) == 1\n",
    "        ), f'Precomputed path error for {region_i}/{region.module_id} [file {f\"all_tm_region_very_conf_*_{region.module_id}.pkl\"}]: # of results is {len(all_paths)} ({\",\".join(map(str, all_paths))})'\n",
    "        with open(all_paths[0], \"rb\") as f:\n",
    "            distances_list = pickle.load(f)\n",
    "        for i, j, dist in distances_list:\n",
    "            dist_mat[i, j] = dist\n",
    "            dist_mat[j, i] = dist\n",
    "    if selected_indices is not None:\n",
    "        orig_idx_2_new = {orig_i: i for i, orig_i in enumerate(selected_indices)}\n",
    "        dist_mat_subset = -np.ones((len(selected_indices), len(selected_indices)))\n",
    "        for i, row_idx in enumerate(selected_indices):\n",
    "            for i_j_delta, col_idx in enumerate(selected_indices[i + 1 :]):\n",
    "                dist_mat[row_idx, col_idx]\n",
    "                j = i + 1 + i_j_delta\n",
    "                assert orig_idx_2_new[row_idx] == i and orig_idx_2_new[col_idx] == j\n",
    "                dist_mat_subset[i, j] = dist\n",
    "                dist_mat_subset[j, i] = dist\n",
    "        return dist_mat_subset\n",
    "    return dist_mat\n",
    "\n",
    "\n",
    "with open(\n",
    "    f\"data/tps_domains_and_comparisons/regions_completed_very_confident_all_ALL.pkl\",\n",
    "    \"rb\",\n",
    ") as f:\n",
    "    regions = pickle.load(f)\n",
    "\n",
    "dist_mat = get_dist_mat_precomputed(regions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7057a6a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_mat = 1 - dist_mat\n",
    "np.fill_diagonal(dist_mat, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31037260",
   "metadata": {},
   "outputs": [],
   "source": [
    "known_non_neg_bool_idx = np.array(\n",
    "    [\n",
    "        (\n",
    "            list(id_2_type_set[uni_id])[0]\n",
    "            if uni_id in id_2_type_set and len(id_2_type_set[uni_id])\n",
    "            else \"\"\n",
    "        )\n",
    "        not in {\"Unknown\", \"Negative\", \"\"}\n",
    "        for uni_id, _ in regions\n",
    "    ]\n",
    ")\n",
    "all_ids_list = [regions[i][0] for i in range(len(regions)) if known_non_neg_bool_idx[i]]\n",
    "dist_mat = dist_mat[:, known_non_neg_bool_idx][known_non_neg_bool_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6268589",
   "metadata": {},
   "outputs": [],
   "source": [
    "regions = [regions[i] for i in range(len(regions)) if known_non_neg_bool_idx[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da4bd06c",
   "metadata": {},
   "outputs": [],
   "source": [
    "reducer_pca = PCA(n_components=2, random_state=42)\n",
    "pca_coord_dom = reducer_pca.fit_transform(dist_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a42c1e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "core_class_names = [\n",
    "    \"tetra\",\n",
    "    \"sesquar\",\n",
    "    \"tri (Class I)\",\n",
    "    \"sester\",\n",
    "    \"di (Class I)\",\n",
    "    \"sesq\",\n",
    "    \"mono\",\n",
    "    \"isoprenyl diphosphate synthase\",\n",
    "    \"hemi\",\n",
    "]\n",
    "\n",
    "cmap = matplotlib.colormaps[\"tab20\"]\n",
    "colors = cmap(np.linspace(0, 1, 20))\n",
    "reaction_class_2_color = {\n",
    "    class_name: colors[2 * i] for i, class_name in enumerate(core_class_names)\n",
    "}\n",
    "reaction_class_2_color[\"di (Class II)\"] = colors[9]\n",
    "reaction_class_2_color[\"tri (Class II)\"] = colors[5]\n",
    "\n",
    "cmap2 = matplotlib.colormaps[\"Dark2\"]\n",
    "colors2 = cmap2(np.linspace(0, 1, 8))\n",
    "reaction_class_2_color[\"tri (squalene synthase)\"] = colors2[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f341038b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(\n",
    "    all_ids_list,\n",
    "    coord,\n",
    "    title_str,\n",
    "    file_name,\n",
    "    id_2_substrates_set,\n",
    "    double_domain_ids,\n",
    "    domain_order=None,\n",
    "    point_labels=None,\n",
    "    is_jittered=True,\n",
    "    jitter_param=0.005,\n",
    "    dot_size=22,\n",
    "    legend_anchor=(0.3005, 0.0),\n",
    "    classes_order=[\n",
    "        \"tetra\",\n",
    "        \"sesquar\",\n",
    "        \"tri (Class I)\",\n",
    "        \"tri (Class II)\",\n",
    "        \"tri (squalene synthase)\",\n",
    "        \"sester\",\n",
    "        \"di (Class I)\",\n",
    "        \"di (Class II)\",\n",
    "        \"sesq\",\n",
    "        \"mono\",\n",
    "        \"hemi\",\n",
    "        \"isoprenyl diphosphate synthase\",\n",
    "    ],\n",
    "    reaction_class_2_color=reaction_class_2_color,\n",
    "    no_interm_names=False,\n",
    "    plot_size=(10, 10),\n",
    "    legend_title=\"TPS Type\",\n",
    "    categories_to_show=None,\n",
    "    color_double_domains_only=True,\n",
    "    mark_double_alpha_points=False,\n",
    "):\n",
    "\n",
    "    coords = [coord[:, 0], coord[:, 1]]\n",
    "    _, ax = plt.subplots(1, 1, figsize=plot_size)\n",
    "\n",
    "    class_2_x = defaultdict(list)\n",
    "    class_2_y = defaultdict(list)\n",
    "    class_2_is_double_domain = defaultdict(list)\n",
    "    class_2_domain_order = defaultdict(list)\n",
    "    single_substr_classes = set()\n",
    "    double_substr_classes = set()\n",
    "    all_observed_substr_classes = set()\n",
    "    x_min, x_max = float(\"inf\"), -float(\"inf\")\n",
    "    y_min, y_max = float(\"inf\"), -float(\"inf\")\n",
    "\n",
    "    for inst_i, uni_id in enumerate(all_ids_list):\n",
    "        x, y = coords[0][inst_i], coords[1][inst_i]\n",
    "        try:\n",
    "            instance_labels = (\n",
    "                id_2_substrates_set[uni_id]\n",
    "                if point_labels is None\n",
    "                else [point_labels[inst_i]]\n",
    "            )\n",
    "        except KeyError:\n",
    "            continue\n",
    "        if len([label for label in instance_labels if label != \"\"]) == 1:\n",
    "            class_name = list(instance_labels)[0]\n",
    "            if class_name not in {\"Unknown\", \"Negative\", \"\"}:\n",
    "                single_substr_classes.add(class_name)\n",
    "                all_observed_substr_classes.add(class_name)\n",
    "                class_2_x[class_name].append(x)\n",
    "                class_2_y[class_name].append(y)\n",
    "                class_2_is_double_domain[class_name].append(uni_id in double_domain_ids)\n",
    "                if domain_order is not None:\n",
    "                    class_2_domain_order[class_name].append(domain_order[inst_i])\n",
    "                else:\n",
    "                    class_2_domain_order[class_name].append(0)\n",
    "                x_min = min(x, x_min)\n",
    "                x_max = max(x, x_max)\n",
    "                y_min = min(y, y_min)\n",
    "                y_max = max(y, y_max)\n",
    "        else:\n",
    "            largest_pair = sorted(\n",
    "                [label for label in instance_labels if label in classes_order],\n",
    "                key=lambda x: classes_order.index(x),\n",
    "            )[:2]\n",
    "            if len(largest_pair) == 2:\n",
    "                class_name = \",\".join(largest_pair)\n",
    "                all_observed_substr_classes = all_observed_substr_classes.union(\n",
    "                    set(largest_pair)\n",
    "                )\n",
    "                double_substr_classes.add(class_name)\n",
    "                class_2_x[class_name].append(x)\n",
    "                class_2_y[class_name].append(y)\n",
    "                class_2_is_double_domain[class_name].append(uni_id in double_domain_ids)\n",
    "                if domain_order is not None:\n",
    "                    class_2_domain_order[class_name].append(domain_order[inst_i])\n",
    "                else:\n",
    "                    class_2_domain_order[class_name].append(0)\n",
    "                x_min = min(x, x_min)\n",
    "                x_max = max(x, x_max)\n",
    "                y_min = min(y, y_min)\n",
    "                y_max = max(y, y_max)\n",
    "\n",
    "    class_2_is_double_domain = {\n",
    "        class_name: np.array(vals)\n",
    "        for class_name, vals in class_2_is_double_domain.items()\n",
    "    }\n",
    "    class_2_domain_order = {\n",
    "        class_name: np.array(vals) for class_name, vals in class_2_domain_order.items()\n",
    "    }\n",
    "\n",
    "    legend_handles = []\n",
    "\n",
    "    missing_classes = set()\n",
    "\n",
    "    for substr_class in classes_order:  # [::-1]:\n",
    "        if substr_class in single_substr_classes:\n",
    "            df = pd.DataFrame(\n",
    "                {\"x\": class_2_x[substr_class], \"y\": class_2_y[substr_class]}\n",
    "            )\n",
    "            df_1dom = df[~class_2_is_double_domain[substr_class]]\n",
    "            df_2dom_1st = df[\n",
    "                class_2_is_double_domain[substr_class]\n",
    "                & (class_2_domain_order[substr_class] == 0)\n",
    "            ]\n",
    "            df_2dom_2st = df[\n",
    "                class_2_is_double_domain[substr_class]\n",
    "                & (class_2_domain_order[substr_class] == 1)\n",
    "            ]\n",
    "            show_class = (\n",
    "                categories_to_show is None or substr_class in categories_to_show\n",
    "            )\n",
    "            legend_handles.append(\n",
    "                ax.scatter(\n",
    "                    df_1dom[\"x\"],\n",
    "                    df_1dom[\"y\"],\n",
    "                    s=dot_size,\n",
    "                    color=reaction_class_2_color[substr_class]\n",
    "                    if show_class and not color_double_domains_only\n",
    "                    else \"black\",\n",
    "                    edgecolors=\"black\",\n",
    "                    linewidths=0.1\n",
    "                    if show_class and not color_double_domains_only\n",
    "                    else 0.1,\n",
    "                    marker=MarkerStyle(\n",
    "                        \"o\",\n",
    "                        fillstyle=\"full\"\n",
    "                        if show_class and not color_double_domains_only\n",
    "                        else \"none\",\n",
    "                    ),\n",
    "                )\n",
    "            )\n",
    "            ax.scatter(\n",
    "                df_2dom_1st[\"x\"],\n",
    "                df_2dom_1st[\"y\"],\n",
    "                s=2 * dot_size if mark_double_alpha_points else dot_size,\n",
    "                color=reaction_class_2_color[substr_class] if show_class else \"black\",\n",
    "                edgecolors=\"black\",\n",
    "                linewidths=0.1 if show_class and mark_double_alpha_points else 0.1,\n",
    "                marker=MarkerStyle(\"o\", fillstyle=\"full\" if show_class else \"none\"),\n",
    "            )\n",
    "            ax.scatter(\n",
    "                df_2dom_2st[\"x\"],\n",
    "                df_2dom_2st[\"y\"],\n",
    "                s=2 * dot_size if mark_double_alpha_points else dot_size,\n",
    "                color=reaction_class_2_color[substr_class] if show_class else \"black\",\n",
    "                edgecolors=\"black\",\n",
    "                linewidths=0.1 if show_class and mark_double_alpha_points else 0.1,\n",
    "                marker=MarkerStyle(\n",
    "                    \"s\" if mark_double_alpha_points else \"o\",\n",
    "                    fillstyle=\"full\" if show_class else \"none\",\n",
    "                ),\n",
    "            )\n",
    "        elif substr_class in all_observed_substr_classes and (\n",
    "            categories_to_show is None or substr_class in categories_to_show\n",
    "        ):\n",
    "            df = pd.DataFrame({\"x\": [x_max * 2], \"y\": [y_max * 2]})\n",
    "            legend_handles.append(\n",
    "                ax.scatter(\n",
    "                    df[\"x\"],\n",
    "                    df[\"y\"],\n",
    "                    s=dot_size,\n",
    "                    color=reaction_class_2_color[substr_class],\n",
    "                    marker=\"o\",\n",
    "                )\n",
    "            )\n",
    "        else:\n",
    "            missing_classes.add(substr_class)\n",
    "\n",
    "    if not no_interm_names:\n",
    "        double_substr_classess_in_order = sorted(\n",
    "            [label for label in double_substr_classes],\n",
    "            key=lambda x: -classes_order.index(x.split(\",\")[0]),\n",
    "        )\n",
    "        for double_substr_class in double_substr_classess_in_order:\n",
    "            first_class, second_class = double_substr_class.split(\",\")\n",
    "            df = pd.DataFrame(\n",
    "                {\n",
    "                    \"x\": class_2_x[double_substr_class],\n",
    "                    \"y\": class_2_y[double_substr_class],\n",
    "                }\n",
    "            )\n",
    "            df_1dom = df[~class_2_is_double_domain[double_substr_class]]\n",
    "            df_2dom_1st = df[\n",
    "                class_2_is_double_domain[double_substr_class]\n",
    "                & (class_2_domain_order[double_substr_class] == 0)\n",
    "            ]\n",
    "            df_2dom_2st = df[\n",
    "                class_2_is_double_domain[double_substr_class]\n",
    "                & (class_2_domain_order[double_substr_class] == 1)\n",
    "            ]\n",
    "            show_2nd = categories_to_show is None or second_class in categories_to_show\n",
    "            ax.scatter(\n",
    "                df_1dom[\"x\"],\n",
    "                df_1dom[\"y\"],\n",
    "                s=dot_size,\n",
    "                color=reaction_class_2_color[second_class]\n",
    "                if show_2nd and not color_double_domains_only\n",
    "                else \"black\",\n",
    "                linewidths=0.1 if show_2nd and not color_double_domains_only else 0.1,\n",
    "                marker=MarkerStyle(\n",
    "                    \"o\",\n",
    "                    fillstyle=\"left\"\n",
    "                    if show_2nd and not color_double_domains_only\n",
    "                    else \"none\",\n",
    "                ),\n",
    "            )\n",
    "            show_1st = categories_to_show is None or first_class in categories_to_show\n",
    "            ax.scatter(\n",
    "                df_1dom[\"x\"],\n",
    "                df_1dom[\"y\"],\n",
    "                s=dot_size,\n",
    "                color=reaction_class_2_color[first_class]\n",
    "                if show_1st and not color_double_domains_only\n",
    "                else \"black\",\n",
    "                edgecolors=\"black\",\n",
    "                linewidths=0.1 if show_1st and not color_double_domains_only else 0.1,\n",
    "                marker=MarkerStyle(\n",
    "                    \"o\",\n",
    "                    fillstyle=\"right\"\n",
    "                    if show_1st and not color_double_domains_only\n",
    "                    else \"none\",\n",
    "                ),\n",
    "            )\n",
    "            ax.scatter(\n",
    "                df_2dom_1st[\"x\"],\n",
    "                df_2dom_1st[\"y\"],\n",
    "                s=2 * dot_size if mark_double_alpha_points else dot_size,\n",
    "                color=reaction_class_2_color[first_class] if show_1st else \"black\",\n",
    "                edgecolors=\"black\",\n",
    "                linewidths=0.1 if show_1st and mark_double_alpha_points else 0.1,\n",
    "                marker=MarkerStyle(\"o\", fillstyle=\"full\" if show_1st else \"none\"),\n",
    "            )\n",
    "            ax.scatter(\n",
    "                df_2dom_2st[\"x\"],\n",
    "                df_2dom_2st[\"y\"],\n",
    "                s=2 * dot_size if mark_double_alpha_points else dot_size,\n",
    "                color=reaction_class_2_color[first_class] if show_1st else \"black\",\n",
    "                edgecolors=\"black\",\n",
    "                linewidths=0.1 if show_1st and mark_double_alpha_points else 0.1,\n",
    "                marker=MarkerStyle(\n",
    "                    \"s\" if mark_double_alpha_points else \"o\",\n",
    "                    fillstyle=\"full\" if show_1st else \"none\",\n",
    "                ),\n",
    "            )\n",
    "\n",
    "    #################### 2nd domain\n",
    "    df = pd.DataFrame({\"x\": [x_max * 2], \"y\": [y_max * 2]})\n",
    "    legend_handles.append(\n",
    "        ax.scatter(\n",
    "            df[\"x\"],\n",
    "            df[\"y\"],\n",
    "            s=2 * dot_size,\n",
    "            color=\"black\",\n",
    "            marker=MarkerStyle(\"s\", fillstyle=\"none\"),\n",
    "            edgecolors=\"black\",\n",
    "            linewidths=0.1,\n",
    "        )\n",
    "    )\n",
    "\n",
    "    legend_handles.append(\n",
    "        ax.scatter(\n",
    "            df[\"x\"],\n",
    "            df[\"y\"],\n",
    "            s=2 * dot_size,\n",
    "            color=\"black\",\n",
    "            marker=MarkerStyle(\"o\", fillstyle=\"none\"),\n",
    "            edgecolors=\"black\",\n",
    "            linewidths=0.1,\n",
    "        )\n",
    "    )\n",
    "\n",
    "    legend = ax.legend(\n",
    "        legend_handles,\n",
    "        [\n",
    "            name.replace(\"-int\", \"-intermediate\")\n",
    "            for name in classes_order\n",
    "            if name not in missing_classes\n",
    "        ]\n",
    "        + (\n",
    "            [\"2nd $\\\\alpha$ domain\", \"1st $\\\\alpha$ domain\"]\n",
    "            if color_double_domains_only\n",
    "            else []\n",
    "        ),\n",
    "        loc=\"lower left\",\n",
    "        title=\"Substrate\",\n",
    "        bbox_to_anchor=legend_anchor,\n",
    "        ncol=1,\n",
    "    )\n",
    "    legend.get_frame().set_alpha(None)\n",
    "    legend.get_frame().set_facecolor((1, 1, 1, 1))\n",
    "    ax.set_xlim((x_min - np.abs(x_min) / 10, x_max + np.abs(x_max) / 10))\n",
    "    ax.set_ylim((y_min - np.abs(y_min) / 10, y_max + np.abs(y_max) / 10))\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.title(title_str, fontsize=22, y=1.05)\n",
    "    plt.savefig(f\"{file_name}.eps\", format=\"eps\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "976d38be",
   "metadata": {},
   "outputs": [],
   "source": [
    "domain_order = [int(region.module_id.split(\"_\")[-1]) for _, region in regions]\n",
    "double_domain_ids = {\n",
    "    uni_id for uni_id, count in Counter(all_ids_list).items() if count > 1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48ed6a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(\n",
    "    all_ids_list,\n",
    "    pca_coord_dom,\n",
    "    f\"PCA based on TM-score\\n{sum(reducer_pca.explained_variance_ratio_)*100:.0f}% of variation captured\",\n",
    "    \"pca_tmscore\",\n",
    "    domain_order=domain_order,\n",
    "    double_domain_ids=double_domain_ids,\n",
    "    no_interm_names=False,\n",
    "    color_double_domains_only=False,\n",
    "    id_2_substrates_set=id_2_type_set,\n",
    "    jitter_param=0.005,\n",
    "    legend_anchor=(1.05, 0.0),\n",
    "    dot_size=50,\n",
    "    plot_size=(5, 5),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a88649f0",
   "metadata": {},
   "source": [
    "# Medoids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb0931e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "color_discrete_sequence = (\n",
    "    px.colors.qualitative.Dark24\n",
    "    + px.colors.qualitative.Light24\n",
    "    + px.colors.qualitative.Pastel1\n",
    "    + px.colors.qualitative.Pastel2\n",
    "    + px.colors.qualitative.Set3\n",
    ")\n",
    "silhouette_avg_all = []\n",
    "distortions = []\n",
    "max_silhouette_avg = -float(\"inf\")\n",
    "n_medoids_best = 1\n",
    "rand_seed_best = None\n",
    "\n",
    "for n_medoids in trange(2, 20):\n",
    "    km_ = KMedoids(\n",
    "        n_medoids, method=\"pam\", metric=\"precomputed\", init=\"k-medoids++\", max_iter=1000\n",
    "    )\n",
    "\n",
    "    km_.fit(dist_mat)\n",
    "    distortions.append(km_.inertia_)\n",
    "    cluster_labels = km_.labels_\n",
    "    silhouette_avg = silhouette_score(dist_mat, cluster_labels, metric=\"precomputed\")\n",
    "    if silhouette_avg > 0:\n",
    "        sample_silhouette_values = silhouette_samples(\n",
    "            dist_mat, cluster_labels, metric=\"precomputed\"\n",
    "        )\n",
    "        is_ok_each_cluster = True\n",
    "        for i in range(n_medoids):\n",
    "            # Aggregate the silhouette scores for samples belonging to\n",
    "            # cluster i, and sort them\n",
    "            ith_cluster_silhouette_values = sample_silhouette_values[\n",
    "                cluster_labels == i\n",
    "            ]\n",
    "            repr_group_size = sum(cluster_labels == i)\n",
    "        silhouette_avg_all.append(silhouette_avg)\n",
    "        if is_ok_each_cluster and silhouette_avg > max_silhouette_avg:\n",
    "            max_silhouette_avg = silhouette_avg\n",
    "            km = km_\n",
    "            n_medoids_best = n_medoids\n",
    "km = KMedoids(n_medoids_best, method=\"pam\", metric=\"precomputed\", max_iter=100000)\n",
    "km.fit(dist_mat)\n",
    "cluster_labels = km.labels_\n",
    "\n",
    "sample_silhouette_values = silhouette_samples(\n",
    "    dist_mat, cluster_labels, metric=\"precomputed\"\n",
    ")\n",
    "silh_score_this = silhouette_score(dist_mat, cluster_labels, metric=\"precomputed\")\n",
    "\n",
    "_, ax = plt.subplots(figsize=(4, 3))\n",
    "y_lower = 10\n",
    "for i in range(n_medoids_best):\n",
    "    ith_cluster_silhouette_values = sample_silhouette_values[cluster_labels == i]\n",
    "    ith_cluster_silhouette_values.sort()\n",
    "    size_cluster_i = ith_cluster_silhouette_values.shape[0]\n",
    "    y_upper = y_lower + size_cluster_i\n",
    "\n",
    "    color = color_discrete_sequence[i % n_medoids_best]\n",
    "    ax.fill_betweenx(\n",
    "        np.arange(y_lower, y_upper),\n",
    "        0,\n",
    "        ith_cluster_silhouette_values,\n",
    "        facecolor=color,\n",
    "        edgecolor=color,\n",
    "        alpha=0.7,\n",
    "    )\n",
    "\n",
    "    ax.text(-0.05, y_lower + 0.2 * size_cluster_i, str(i + 1))\n",
    "\n",
    "    y_lower = y_upper + 10\n",
    "\n",
    "ax.set_title(\"The silhouette plot for\\noptimal $\\\\alpha$-domain medoids\", fontsize=14)\n",
    "ax.set_xlabel(\"The silhouette coefficient values\", fontsize=10)\n",
    "ax.set_ylabel(\"Cluster label\", fontsize=10)\n",
    "ax.set_yticks([])\n",
    "ax.set_xticks([0, 0.2, 0.4, 0.6, 0.8, 1])\n",
    "\n",
    "medoid_orig_indices = km.medoid_indices_\n",
    "plt.savefig(\"silhouette_a.eps\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2445f69-e8f3-485e-9ba6-c4e730475cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, ax = plt.subplots(figsize=(5, 3))\n",
    "\n",
    "plt.plot(range(2, 20), silhouette_avg_all, marker=\"o\")\n",
    "\n",
    "ax.axvline(x=5, ymax=0.95, color=\"red\", linestyle=\"--\")\n",
    "\n",
    "ax.set_title(\n",
    "    \"Selection of optimal number of medoids\\n via silhouette analysis for all domains\",\n",
    "    fontsize=14,\n",
    ")\n",
    "ax.set_xlabel(\"Number of medoids\", fontsize=10)\n",
    "ax.set_ylabel(\"Average silhouette coefficient\", fontsize=10)\n",
    "ax.set_xticks(list(range(2, 20)))\n",
    "ax.legend([\"Individual experiments\", \"Optimal medoid count\"])\n",
    "\n",
    "plt.savefig(\"silhouette_analysis_all.pdf\", bbox_inches=\"tight\", dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15e98b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "km = KMedoids(5, method=\"pam\", metric=\"precomputed\", max_iter=10000, init=\"k-medoids++\")\n",
    "km.fit(dist_mat)\n",
    "cluster_labels = km.labels_\n",
    "medoid_orig_indices = km.medoid_indices_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ab5661e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cmap = matplotlib.colormaps[\"tab20\"]\n",
    "colors = cmap(np.linspace(0, 1, 20))\n",
    "reaction_class_2_color = {\n",
    "    class_name: colors[i]\n",
    "    for i, class_name in enumerate([str(i) for i in set(km.labels_)])\n",
    "}\n",
    "\n",
    "plot(\n",
    "    all_ids_list,\n",
    "    pca_coord_dom,\n",
    "    f\"K-medoids clustering of all TPS domains\\nPCA based on TM-score\\n{sum(reducer_pca.explained_variance_ratio_)*100:.0f}% of variation captured\",\n",
    "    \"k_medoids_pca\",\n",
    "    domain_order=domain_order,\n",
    "    double_domain_ids=double_domain_ids,\n",
    "    no_interm_names=False,\n",
    "    color_double_domains_only=False,\n",
    "    id_2_substrates_set=id_2_type_set,\n",
    "    reaction_class_2_color=reaction_class_2_color,\n",
    "    point_labels=[str(i) for i in km.labels_],\n",
    "    classes_order=[str(i) for i in sorted(set(km.labels_))],\n",
    "    jitter_param=0.00,\n",
    "    legend_anchor=(1.05, 0.0),\n",
    "    dot_size=50,\n",
    "    plot_size=(5, 5),\n",
    ")\n",
    "plt.savefig(\"medoids_all.pdf\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4c79f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "medoid_2_regions = defaultdict(set)\n",
    "\n",
    "for medoid_id, module_id in zip(\n",
    "    km.labels_, [region.module_id for _, region in regions]\n",
    "):\n",
    "    medoid_2_regions[medoid_id].add(module_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90985c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "medoid_2_domains = defaultdict(list)\n",
    "for medoid_id, module_id in zip(km.labels_, [region.domain for _, region in regions]):\n",
    "    medoid_2_domains[medoid_id].append(module_id)\n",
    "\n",
    "{medoid: Counter(vals) for medoid, vals in medoid_2_domains.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ff93fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/tps_domains_and_comparisons/medoid_2_regions.pkl\", \"wb\") as file:\n",
    "    pickle.dump(medoid_2_regions, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cac8683f-f281-4454-9ad8-030f236a4a2f",
   "metadata": {},
   "source": [
    "# HDBSCAN clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f14ed544",
   "metadata": {},
   "outputs": [],
   "source": [
    "hdbscan_clusterer = hdbscan.HDBSCAN(metric=\"precomputed\")\n",
    "hdbscan_clusterer.fit(dist_mat)\n",
    "\n",
    "\n",
    "def fill_noise_with_closest_label(labels_, dist_mat, n_neighbs=3):\n",
    "    for i, val in enumerate(labels_):\n",
    "        if labels_[i] == -1:\n",
    "            label_counts = defaultdict(int)\n",
    "            neighbours = np.argsort(dist_mat[i, :])[:n_neighbs]\n",
    "            for neighb_i in neighbours:\n",
    "                if labels_[neighb_i] != -1:\n",
    "                    label_counts[labels_[neighb_i]] += 1\n",
    "            labels_[i] = max(label_counts.items(), key=lambda el: el[1])[0]\n",
    "\n",
    "\n",
    "fill_noise_with_closest_label(hdbscan_clusterer.labels_, dist_mat)\n",
    "reaction_class_2_color = {\n",
    "    class_name: colors[i]\n",
    "    for i, class_name in enumerate([str(i) for i in set(hdbscan_clusterer.labels_)])\n",
    "}\n",
    "\n",
    "plot(\n",
    "    all_ids_list,\n",
    "    pca_coord_dom,\n",
    "    f\"HDBSCAN clustering of all detected domains\\nPCA based on precise TM-score\\n{sum(reducer_pca.explained_variance_ratio_)*100:.0f}% of variation captured\",\n",
    "    \"k_medoids_pca\",\n",
    "    domain_order=domain_order,\n",
    "    double_domain_ids=double_domain_ids,\n",
    "    no_interm_names=False,\n",
    "    color_double_domains_only=False,\n",
    "    id_2_substrates_set=id_2_type_set,\n",
    "    reaction_class_2_color=reaction_class_2_color,\n",
    "    point_labels=[str(i) for i in hdbscan_clusterer.labels_],\n",
    "    classes_order=[str(i) for i in sorted(set(hdbscan_clusterer.labels_))],\n",
    "    jitter_param=0.00,\n",
    "    legend_anchor=(1.05, 0.0),\n",
    "    dot_size=50,\n",
    "    plot_size=(5, 5),\n",
    ")\n",
    "plt.savefig(\"medoids_all.pdf\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9c1a788-db8d-4102-afc3-e1f2642501f3",
   "metadata": {},
   "source": [
    "# Separate $\\alpha$ domains analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41dbf100-098a-41af-8b18-77b4144afce8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fef1557b",
   "metadata": {},
   "outputs": [],
   "source": [
    "hdbscan_tree = hdbscan_clusterer.condensed_tree_.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce7f1fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.colors as colors\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def truncate_colormap(cmap, minval=0.0, maxval=1.0, n=40):\n",
    "    new_cmap = colors.LinearSegmentedColormap.from_list(\n",
    "        \"trunc({n},{a:.2f},{b:.2f})\".format(n=cmap.name, a=minval, b=maxval),\n",
    "        cmap(np.linspace(minval, maxval, n)),\n",
    "    )\n",
    "    return new_cmap\n",
    "\n",
    "\n",
    "pink_cmap = truncate_colormap(cm.get_cmap(\"BrBG\", 80), 0, 0.5)\n",
    "pink_cmap = cm.get_cmap(\"PiYG\", 80)\n",
    "brown_cmap = cm.get_cmap(\"PuOr\", 120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b247c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "for alpha_type_i in range(4):\n",
    "    type_bool_idx = km.labels_ == alpha_type_i\n",
    "    subtype_vals = set(hdbscan_clusterer.labels_[type_bool_idx])\n",
    "    for subtype in subtype_vals:\n",
    "        if subtype != -1:\n",
    "            alpha_type = i_2_name[alpha_type_i]\n",
    "            print(\n",
    "                f\"Alpha{alpha_type}-{subtype}, inside alpha type #: {sum(np.logical_and(type_bool_idx, hdbscan_clusterer.labels_ == subtype))}, outside #: { {sum(np.logical_and(np.logical_not(type_bool_idx), hdbscan_clusterer.labels_ == subtype))}}\"\n",
    "            )\n",
    "\n",
    "    print(\"=\" * 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61a4627e",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_type_subtype_2_module_ids = dict()\n",
    "for alpha_type_i in range(4):\n",
    "    type_bool_idx = km.labels_ == alpha_type_i\n",
    "    subtype_vals = set(hdbscan_clusterer.labels_[type_bool_idx])\n",
    "    type_i = 0\n",
    "    for subtype in subtype_vals:\n",
    "        if subtype != -1:\n",
    "            inside_count = sum(\n",
    "                np.logical_and(type_bool_idx, hdbscan_clusterer.labels_ == subtype)\n",
    "            )\n",
    "            if inside_count > 2:\n",
    "                alpha_type = i_2_name[alpha_type_i]\n",
    "                print(\n",
    "                    f\"Alpha{alpha_type}-{['A', 'B', 'C', 'D', 'E', 'F'][type_i]}, inside alpha type #: {inside_count}, outside #: { {sum(np.logical_and(np.logical_not(type_bool_idx), hdbscan_clusterer.labels_ == subtype))}}\"\n",
    "                )\n",
    "                alpha_type_subtype_2_module_ids[\n",
    "                    (alpha_type, [\"A\", \"B\", \"C\", \"D\", \"E\", \"F\"][type_i])\n",
    "                ] = {\n",
    "                    region.module_id\n",
    "                    for i, (_, region) in enumerate(regions)\n",
    "                    if hdbscan_clusterer.labels_[i] == subtype\n",
    "                }\n",
    "                type_i += 1\n",
    "    print(\"=\" * 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18bcea0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/alpha_type_subtype_2_module_ids.pkl\", \"wb\") as f:\n",
    "    pickle.dump(alpha_type_subtype_2_module_ids, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c55ef847",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5be9e0c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_color_range_i(tmscore_diff, n_bins=25, max_tmscore_diff=0.4, reverse=False):\n",
    "    delta = max_tmscore_diff / n_bins\n",
    "    result = int(n_bins - tmscore_diff // delta)\n",
    "    if reverse:\n",
    "        return n_bins - result\n",
    "    return result + 10\n",
    "\n",
    "\n",
    "medoid_cmaps = [\n",
    "    pink_cmap,\n",
    "    brown_cmap,\n",
    "    cm.get_cmap(\"Greys\", 40),\n",
    "    cm.get_cmap(\"Greens\", 40),\n",
    "]  # cm.get_cmap(\"Oranges\", 40),\n",
    "reverse_cmaps = [True, True, False, False]\n",
    "\n",
    "\n",
    "def plot_medoids_zones(\n",
    "    distmatrix,\n",
    "    medoid_orig_indices,\n",
    "    max_tmscore_diff,\n",
    "    all_ids_list,\n",
    "    regions_list,\n",
    "    coord,\n",
    "    title_str,\n",
    "    file_name,\n",
    "    is_jittered=True,\n",
    "    jitter_param=0.005,\n",
    "    dot_size=22,\n",
    "    legend_anchor=(0.3005, 0.0),\n",
    "    no_interm_names=False,\n",
    "    plot_size=(10, 10),\n",
    "    legend_title=\"TPS Type\",\n",
    "    categories_to_show=None,\n",
    "    hide_legend=False,\n",
    "):\n",
    "\n",
    "    coords = (\n",
    "        [jitter(coord[:, 0], jitter_param), jitter(coord[:, 1], jitter_param)]\n",
    "        if is_jittered\n",
    "        else [coord[:, 0], coord[:, 1]]\n",
    "    )\n",
    "    _, ax = plt.subplots(1, 1, figsize=plot_size)\n",
    "\n",
    "    class_2_x = defaultdict(list)\n",
    "    class_2_y = defaultdict(list)\n",
    "    single_substr_classes = set()\n",
    "    double_substr_classes = set()\n",
    "    all_observed_substr_classes = set()\n",
    "    x_min, x_max = float(\"inf\"), -float(\"inf\")\n",
    "    y_min, y_max = float(\"inf\"), -float(\"inf\")\n",
    "\n",
    "    main_medoid_2_ids = defaultdict(list)\n",
    "    medoids_all = []\n",
    "    for inst_i, uni_id in enumerate(all_ids_list):\n",
    "        x, y = coords[0][inst_i], coords[1][inst_i]\n",
    "        instance_labels = []\n",
    "        instance_label_dists = []\n",
    "        for medoid_i, medoid_inst_i in enumerate(medoid_orig_indices):\n",
    "            dist_to_medoid = distmatrix[medoid_inst_i, inst_i]\n",
    "            if dist_to_medoid < max_tmscore_diff:\n",
    "                instance_label_dists.append(dist_to_medoid)\n",
    "                instance_labels.append(medoid_i)\n",
    "\n",
    "        if len(instance_labels) == 1:\n",
    "            medoid_i = instance_labels[0]\n",
    "            class_name = medoid_cmaps[medoid_i](\n",
    "                get_color_range_i(\n",
    "                    instance_label_dists[0], reverse=reverse_cmaps[medoid_i]\n",
    "                )\n",
    "            )\n",
    "            class_2_x[class_name].append(x)\n",
    "            class_2_y[class_name].append(y)\n",
    "            single_substr_classes.add(class_name)\n",
    "            main_medoid_2_ids[medoid_i].append(regions_list[inst_i])\n",
    "            medoids_all.append(medoid_i)\n",
    "        elif len(instance_labels) > 1:\n",
    "            largest_pair_indices = sorted(\n",
    "                list(range(len(instance_label_dists))),\n",
    "                key=lambda i: instance_label_dists[i],\n",
    "            )[:2]\n",
    "            largest_pair = [instance_labels[i] for i in largest_pair_indices]\n",
    "\n",
    "            colors = []\n",
    "            for i in largest_pair_indices:\n",
    "                medoid_i = instance_labels[i]\n",
    "                colors.append(\n",
    "                    medoid_cmaps[medoid_i](\n",
    "                        get_color_range_i(\n",
    "                            instance_label_dists[i], reverse=reverse_cmaps[medoid_i]\n",
    "                        )\n",
    "                    )\n",
    "                )\n",
    "                medoids_all.append(medoid_i)\n",
    "            class_name = tuple(colors)\n",
    "            double_substr_classes.add(class_name)\n",
    "            class_2_x[class_name].append(x)\n",
    "            class_2_y[class_name].append(y)\n",
    "            main_medoid_2_ids[instance_labels[largest_pair_indices[0]]].append(\n",
    "                regions_list[inst_i]\n",
    "            )\n",
    "        else:\n",
    "            class_2_x[\"bg\"].append(x)\n",
    "            class_2_y[\"bg\"].append(y)\n",
    "        x_min = min(x, x_min)\n",
    "        x_max = max(x, x_max)\n",
    "        y_min = min(y, y_min)\n",
    "        y_max = max(y, y_max)\n",
    "\n",
    "    print(Counter(medoids_all))\n",
    "\n",
    "    df = pd.DataFrame({\"x\": class_2_x[\"bg\"], \"y\": class_2_y[\"bg\"]})\n",
    "    ax.scatter(\n",
    "        df[\"x\"],\n",
    "        df[\"y\"],\n",
    "        s=dot_size,\n",
    "        color=\"gray\",\n",
    "        linewidths=0.2,\n",
    "        marker=MarkerStyle(\"o\", fillstyle=\"none\"),\n",
    "    )\n",
    "\n",
    "    for double_substr_class in sorted(double_substr_classes, reverse=True):\n",
    "        df = pd.DataFrame(\n",
    "            {\"x\": class_2_x[double_substr_class], \"y\": class_2_y[double_substr_class]}\n",
    "        )\n",
    "        ax.scatter(\n",
    "            df[\"x\"],\n",
    "            df[\"y\"],\n",
    "            s=dot_size,\n",
    "            color=double_substr_class[1],\n",
    "            linewidths=1.5,\n",
    "            marker=MarkerStyle(\"o\", fillstyle=\"right\"),\n",
    "        )\n",
    "        ax.scatter(\n",
    "            df[\"x\"],\n",
    "            df[\"y\"],\n",
    "            s=dot_size,\n",
    "            color=double_substr_class[0],\n",
    "            linewidths=1.5,\n",
    "            marker=MarkerStyle(\"o\", fillstyle=\"left\"),\n",
    "        )\n",
    "    for substr_class in sorted(single_substr_classes, reverse=True):\n",
    "        df = pd.DataFrame({\"x\": class_2_x[substr_class], \"y\": class_2_y[substr_class]})\n",
    "        ax.scatter(\n",
    "            df[\"x\"],\n",
    "            df[\"y\"],\n",
    "            s=dot_size,\n",
    "            color=substr_class,\n",
    "            linewidths=1.5,\n",
    "            marker=MarkerStyle(\"o\", fillstyle=\"full\"),\n",
    "        )\n",
    "\n",
    "    legend_handles = []\n",
    "\n",
    "    missing_classes = set()\n",
    "    for medoid_i, medoid_cmap in enumerate(medoid_cmaps):\n",
    "        df = pd.DataFrame({\"x\": [x_max * 2], \"y\": [y_max * 2]})\n",
    "        legend_handles.append(\n",
    "            ax.scatter(\n",
    "                df[\"x\"],\n",
    "                df[\"y\"],\n",
    "                s=dot_size,\n",
    "                color=medoid_cmap(get_color_range_i(0.1)),\n",
    "                marker=\"o\",\n",
    "            )\n",
    "        )\n",
    "\n",
    "    if not hide_legend:\n",
    "        legend = ax.legend(\n",
    "            legend_handles,\n",
    "            range(len(medoid_cmaps)),\n",
    "            loc=\"lower left\",\n",
    "            title=\"Substrate\",\n",
    "            bbox_to_anchor=legend_anchor,\n",
    "            ncol=1,\n",
    "        )\n",
    "        legend.get_frame().set_alpha(None)\n",
    "        legend.get_frame().set_facecolor((1, 1, 1, 1))\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    print((x_min, x_max))\n",
    "    ax.set_xlim((x_min - np.abs(x_min) / 10, x_max - np.abs(x_max) / 20))\n",
    "    ax.set_ylim((y_min - np.abs(y_min) / 10, y_max + np.abs(y_max) / 10))\n",
    "    return main_medoid_2_ids\n",
    "\n",
    "\n",
    "#     plt.title(title_str, fontsize=22, y=1.05)\n",
    "\n",
    "for thresh in [0.1, 0.2, 0.3, 0.4]:\n",
    "    main_medoid_2_ids = plot_medoids_zones(\n",
    "        dist_mat,\n",
    "        medoid_orig_indices,\n",
    "        thresh,\n",
    "        all_ids_list,\n",
    "        regions,\n",
    "        pca_coord_dom,\n",
    "        f\"PCA based on $\\\\alpha$ domains\",\n",
    "        \"_temp_b_g_medoids\",\n",
    "        jitter_param=0.00,\n",
    "        legend_anchor=(0.15, 0.0),\n",
    "        dot_size=50,\n",
    "        plot_size=(4, 4),\n",
    "        hide_legend=True,\n",
    "    )  # , categories_to_show=['sester', 'polyprenyl synthetase'])\n",
    "\n",
    "    plt.scatter(\n",
    "        pca_coord_dom[km.medoid_indices_, 0],\n",
    "        pca_coord_dom[km.medoid_indices_, 1],\n",
    "        s=100,\n",
    "        c=[\n",
    "            medoid_cmap(get_color_range_i(0.1, reverse=reverse_cmaps[medoid_i]))\n",
    "            for medoid_i, medoid_cmap in enumerate(medoid_cmaps)\n",
    "        ],\n",
    "        linewidths=2,\n",
    "        edgecolors=\"black\",\n",
    "        marker=\"X\",\n",
    "    )\n",
    "    #     plt.title(f'TM-score {thresh}', fontsize=14, y=1.05)\n",
    "    plt.savefig(f\"a_medoids_0{thresh*100}.eps\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73f8e5aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dfe1d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_medoid_2_ids = plot_medoids_zones(\n",
    "    dist_mat,\n",
    "    medoid_orig_indices,\n",
    "    0.5,\n",
    "    all_ids_list,\n",
    "    regions,\n",
    "    pca_coord_dom,\n",
    "    f\"PCA based on $\\\\alpha$ domains\",\n",
    "    \"_temp_b_g_medoids\",\n",
    "    jitter_param=0.00,\n",
    "    legend_anchor=(0.15, 0.0),\n",
    "    dot_size=50,\n",
    "    plot_size=(4, 4),\n",
    "    hide_legend=True,\n",
    ")  # , categories_to_show=['sester', 'polyprenyl synthetase'])\n",
    "\n",
    "id_2_medoid = dict()\n",
    "for medoid, ids in main_medoid_2_ids.items():\n",
    "    for uni_id, _ in ids:\n",
    "        id_2_medoid[uni_id] = medoid\n",
    "point_medoid_ids = [id_2_medoid[i] for i in all_ids_list]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
